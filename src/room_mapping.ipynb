{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from jetbot import Robot\n",
    "import utils\n",
    "import threading\n",
    "import map_utils\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import numpy as np\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "class MapProvider2(traitlets.HasTraits):\n",
    "    value = traitlets.Bytes()\n",
    "\n",
    "    def __init__(self, map_size):\n",
    "        super().__init__()\n",
    "        self.map_size = map_size\n",
    "        # Poniżej przykładowe inicjalne wartości (możesz podmienić na swoje)\n",
    "        self.robot_x = map_size / 2\n",
    "        self.robot_y = map_size / 2\n",
    "        self.map_grid = np.zeros((self.map_size, self.map_size), dtype=int)\n",
    "        self._color_map = {\n",
    "            -1: [169, 169, 169],  # Szary - nieznane\n",
    "             0: [0, 255, 0],      # Zielony - podłoga\n",
    "             1: [255, 250, 205],  # Bardzo jasnożółty\n",
    "             2: [255, 215, 0],    # Żółty\n",
    "             3: [255, 165, 0],    # Pomarańczowy\n",
    "             4: [255, 140, 0],    # Ciemnopomarańczowy\n",
    "             5: [255, 0, 0]       # Czerwony - przeszkoda\n",
    "        }\n",
    "        self.lut = np.array([\n",
    "            [169, 169, 169],  # index 0 => dla map_grid == -1\n",
    "            [0,   255, 0],    # index 1 => dla map_grid ==  0\n",
    "            [255, 250, 205],  # index 2 => dla map_grid ==  1\n",
    "            [255, 215, 0],    # index 3 => dla map_grid ==  2\n",
    "            [255, 165, 0],    # index 4 => dla map_grid ==  3\n",
    "            [255, 140, 0],    # index 5 => dla map_grid ==  4\n",
    "            [255, 0,   0],    # index 6 => dla map_grid ==  5\n",
    "        ], dtype=np.uint8)\n",
    "        \n",
    "        # Tworzymy początkowy obraz (wartości w self.value)\n",
    "        self.update_map()\n",
    "        \n",
    "    def _draw_robot_circle(self, img, radius=3, color=(255, 0, 0)):\n",
    "        height, width, _ = img.shape\n",
    "        for dy in range(-radius, radius + 1):\n",
    "            for dx in range(-radius, radius + 1):\n",
    "                # obliczamy odległość euklidesową od środka\n",
    "                if dx*dx + dy*dy <= radius*radius:\n",
    "                    px = int(self.robot_x) + dx\n",
    "                    py = int(self.robot_y) + dy\n",
    "                    # sprawdzamy, czy punkt mieści się w granicach obrazka\n",
    "                    if 0 <= px < width and 0 <= py < height:\n",
    "                        img[py, px] = color\n",
    "\n",
    "    def update_map(self):\n",
    "        # 1) Obliczamy indeksy do tablicy LUT\n",
    "        indices = self.map_grid + 1  # -1 -> 0, 0 -> 1, ..., 5 -> 6\n",
    "        # 2) Pobieramy kolory w trybie wektorowym\n",
    "        img = self.lut[indices]      # shape => (map_size, map_size, 3)\n",
    "        # 3) Rysujemy pozycję robota (bez OpenCV)\n",
    "        self._draw_robot_circle(img)\n",
    "        # 4) Odwracamy pionowo, jeśli chcesz mieć (0,0) na dole\n",
    "        img = np.flipud(img)\n",
    "        # 5) Kodujemy do JPEG\n",
    "        self.value = bgr8_to_jpeg(img)\n",
    "\n",
    "    def set_map(self, map_grid):\n",
    "        self.map_grid = map_grid\n",
    "        self.update_map()\n",
    "    \n",
    "    def set_robot_pos(self, x, y):\n",
    "        self.robot_x = x\n",
    "        self.robot_y = y\n",
    "        self.update_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robot\n",
    "robot = Robot()\n",
    "\n",
    "# Parametry sterowania\n",
    "FORWARD_SPEED = 0.5\n",
    "TURN_SPEED = 0.5\n",
    "DELAY = 0.1     # Czas odświeżania pętli w sekundach\n",
    "MAP_SIZE = 400  # Rozmiar mapy\n",
    "CELL_SIZE = 0.01  # 1 pixel = 0.01 m\n",
    "ROBOT_SIZE = 0.2  # Rozmiar robota w metrach\n",
    "VISION_RANGE = 0.2  # Jak daleko widzi robot (0.2m = 20 pikseli)\n",
    "FORWARD_SPEED_MS = FORWARD_SPEED * 0.16  # Prędkość w metrach na sekundę\n",
    "TURN_ANGLE = 30  # Robot skręca o 30 stopni przy losowym wyborze kierunku\n",
    "\n",
    "# Inicjalizacja mapy (-1 = nieznane)\n",
    "map_grid = np.full((MAP_SIZE, MAP_SIZE), -1)\n",
    "\n",
    "# Pozycja początkowa robota w środku mapy\n",
    "robot_x, robot_y = MAP_SIZE // 2, MAP_SIZE // 2\n",
    "robot_direction = 0  # Kąt obrotu w stopniach (0 = góra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model rozpoznawania podłogi\n",
    "floor_prototype = np.load(\"../models/floor_prototype_full.npy\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Identity()  # Usunięcie ostatniej warstwy\n",
    "model = model.to(device)\n",
    "model.eval()  # Tryb ewaluacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefeeb0f421c439db565b725074389c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widget kamera \n",
    "camera = Camera.instance(width=300, height=300)\n",
    "image = widgets.Image(format='jpeg', width=300, height=300)  # this width and height doesn't necessarily have to match the camera\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e20a96574d0445fa22f4c2c44600f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widget Mapa\n",
    "map_provider = MapProvider2(map_size=MAP_SIZE)\n",
    "map_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "map_link = traitlets.dlink((map_provider, 'value'), (map_widget, 'value'))\n",
    "\n",
    "map_provider.set_robot_pos(robot_x, robot_y)\n",
    "map_provider.set_map(map_grid)\n",
    "\n",
    "display(map_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_and_print(distance=sys.maxsize):\n",
    "    global robot_direction, robot_x, robot_y\n",
    "    last_move_time = time.time()  # Czas ostatniego ruchu do przodu\n",
    "    previous_move_was_forward = False  # Czy ostatni ruch był do przodu?\n",
    "    try:\n",
    "        #print(f\"START X: {robot_x}    Y:{robot_y}\")\n",
    "        has_turned = False  # Flaga: Czy robot ostatnio skręcał?\n",
    "        turn_direction = None  # Kierunek ostatniego skrętu: 'left' lub 'right'\n",
    "\n",
    "        # while True\n",
    "        for step in range(distance):\n",
    "            print(f\"STEP {step:4d}: X: {robot_x:6.2f}, Y: {robot_y:6.2f}, direction: {robot_direction:6.2f}\")\n",
    "            image = Image.fromarray(camera.value)\n",
    "            forward_distance = utils.is_floor(image, model, device, floor_prototype)\n",
    "            #utils.update_map(forward_distance, robot_x, robot_y, robot_direction, map_grid)\n",
    "            #map_provider.set_robot_pos(robot_x, robot_y)\n",
    "            #map_provider.set_map(map_grid)\n",
    "\n",
    "            if previous_move_was_forward:\n",
    "                current_time = time.time()\n",
    "                time_elapsed = current_time - last_move_time\n",
    "                last_move_time = current_time  # Aktualizacja ostatniego ruchu\n",
    "                step_size = FORWARD_SPEED_MS * time_elapsed / CELL_SIZE\n",
    "                # Obliczenie nowej pozycji robota\n",
    "                angle_rad = np.radians(robot_direction)\n",
    "                #robot_x += int(step_size * np.cos(angle_rad))\n",
    "                #robot_y += int(step_size * np.sin(angle_rad))\n",
    "                robot_y += step_size * np.cos(angle_rad)\n",
    "                robot_x += step_size * np.sin(angle_rad)\n",
    "\n",
    "            if forward_distance < 0.175: #and not utils.any_red_20_20(map_grid, robot_direction, robot_x, robot_y):  # Jeśli podłoga wykryta\n",
    "                #print(f\"Podłoga wykryta. Jedź do przodu. Odległość: {forward_distance:.4f}\")\n",
    "                utils.update_map(forward_distance, int(robot_x), int(robot_y), robot_direction, map_grid)\n",
    "                utils.move_forward(robot, FORWARD_SPEED)\n",
    "                last_move_time = time.time()\n",
    "                time.sleep(DELAY)  # Jedź chwilę do przodu\n",
    "                has_turned = False\n",
    "                turn_direction = None\n",
    "                previous_move_was_forward = True\n",
    "            else:\n",
    "                #print(f\"Brak podłogi przed robotem. Odległość: {forward_distance:.4f}\")\n",
    "                previous_move_was_forward = False\n",
    "                utils.stop(robot)\n",
    "                if has_turned:\n",
    "                    pass\n",
    "                    #print(f\"Kontynuowanie skrętu w kierunku: {turn_direction}\")\n",
    "                else:\n",
    "                    # Rozejrzenie się i wybór najlepszego kierunku\n",
    "                    #print(\"Rozejrzenie się...\")\n",
    "                    utils.turn_by_angle(robot, -TURN_ANGLE/2, TURN_SPEED)  # Obrót w lewo o 15°\n",
    "                    image = Image.fromarray(camera.value)\n",
    "                    left_distance = utils.is_floor(image, model, device, floor_prototype)\n",
    "                    utils.turn_by_angle(robot, TURN_ANGLE, TURN_SPEED)  # Obrót w prawo o 30° (15° w prawo od pozycji wyjściowej)\n",
    "                    image = Image.fromarray(camera.value)\n",
    "                    right_distance = utils.is_floor(image, model, device, floor_prototype)\n",
    "                    # Powrót do pozycji początkowej (15° w lewo od pozycji prawej)\n",
    "                    utils.turn_by_angle(robot, -TURN_ANGLE/2, TURN_SPEED)\n",
    "                    # Wybór kierunku\n",
    "                    if left_distance < right_distance:\n",
    "                        #print(f\"Skręt w lewo o {TURN_ANGLE}°. Odległość w lewo: {left_distance:.4f}\")\n",
    "                        turn_direction = 'left'\n",
    "                        forward_distance = left_distance\n",
    "                    else:\n",
    "                        #print(f\"Skręt w prawo o {TURN_ANGLE}°. Odległość w prawo: {right_distance:.4f}\")\n",
    "                        turn_direction = 'right'\n",
    "                        forward_distance = right_distance\n",
    "                    has_turned = True\n",
    "\n",
    "                if turn_direction == 'left':\n",
    "                    utils.update_map(forward_distance, int(robot_x), int(robot_y), robot_direction, map_grid)\n",
    "                    utils.turn_by_angle(robot, -TURN_ANGLE, TURN_SPEED)\n",
    "                    robot_direction = (robot_direction - TURN_ANGLE) % 360\n",
    "                elif turn_direction == 'right':\n",
    "                    utils.update_map(forward_distance, int(robot_x), int(robot_y), robot_direction, map_grid)\n",
    "                    utils.turn_by_angle(robot, TURN_ANGLE, TURN_SPEED)\n",
    "                    robot_direction = (robot_direction + TURN_ANGLE) % 360\n",
    "            \n",
    "            #if i % 10 ==0:\n",
    "            map_provider.set_robot_pos(robot_x, robot_y)\n",
    "            map_provider.set_map(map_grid)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Zatrzymano robota.\")\n",
    "    finally:\n",
    "        utils.stop(robot)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP    0: X: 266.85, Y: 260.28, direction:   0.00\n",
      "STEP    1: X: 266.85, Y: 260.28, direction:   0.00\n",
      "STEP    2: X: 266.85, Y: 261.89, direction:   0.00\n",
      "STEP    3: X: 266.85, Y: 263.47, direction:   0.00\n",
      "STEP    4: X: 266.85, Y: 264.92, direction:   0.00\n",
      "STEP    5: X: 266.85, Y: 266.35, direction:   0.00\n",
      "STEP    6: X: 266.85, Y: 267.79, direction:   0.00\n",
      "STEP    7: X: 266.85, Y: 269.21, direction:   0.00\n",
      "STEP    8: X: 266.85, Y: 270.65, direction:   0.00\n",
      "STEP    9: X: 266.85, Y: 272.07, direction:   0.00\n",
      "STEP   10: X: 266.85, Y: 273.56, direction:   0.00\n",
      "STEP   11: X: 266.85, Y: 274.95, direction:   0.00\n",
      "STEP   12: X: 266.85, Y: 276.38, direction:   0.00\n",
      "STEP   13: X: 266.85, Y: 277.80, direction:   0.00\n",
      "STEP   14: X: 266.85, Y: 279.24, direction:   0.00\n",
      "STEP   15: X: 266.85, Y: 280.62, direction:   0.00\n",
      "STEP   16: X: 266.85, Y: 282.04, direction:   0.00\n",
      "STEP   17: X: 266.85, Y: 283.52, direction:   0.00\n",
      "STEP   18: X: 266.85, Y: 284.96, direction:   0.00\n",
      "STEP   19: X: 266.85, Y: 286.35, direction:   0.00\n",
      "STEP   20: X: 266.85, Y: 287.83, direction:   0.00\n",
      "STEP   21: X: 266.85, Y: 289.24, direction:   0.00\n",
      "STEP   22: X: 266.85, Y: 290.62, direction:   0.00\n",
      "STEP   23: X: 266.85, Y: 292.03, direction:   0.00\n",
      "STEP   24: X: 266.85, Y: 293.49, direction:   0.00\n",
      "STEP   25: X: 266.85, Y: 294.91, direction:   0.00\n",
      "STEP   26: X: 266.85, Y: 296.31, direction:   0.00\n",
      "STEP   27: X: 266.85, Y: 297.75, direction:   0.00\n",
      "STEP   28: X: 266.85, Y: 299.15, direction:   0.00\n",
      "STEP   29: X: 266.85, Y: 300.66, direction:   0.00\n",
      "STEP   30: X: 266.85, Y: 302.17, direction:   0.00\n",
      "STEP   31: X: 266.85, Y: 303.55, direction:   0.00\n",
      "STEP   32: X: 266.85, Y: 304.91, direction:   0.00\n",
      "STEP   33: X: 266.85, Y: 306.28, direction:   0.00\n",
      "STEP   34: X: 266.85, Y: 307.74, direction: 330.00\n",
      "STEP   35: X: 266.85, Y: 307.74, direction: 300.00\n",
      "STEP   36: X: 266.85, Y: 307.74, direction: 300.00\n",
      "STEP   37: X: 265.47, Y: 308.54, direction: 300.00\n",
      "STEP   38: X: 264.18, Y: 309.29, direction: 300.00\n",
      "STEP   39: X: 262.91, Y: 310.02, direction: 300.00\n"
     ]
    }
   ],
   "source": [
    "move_and_print(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.draw_map(robot_x.astype(int), robot_y.astype(int), map_grid.astype(int), MAP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
